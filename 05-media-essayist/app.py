import streamlit as st
import json
import uuid
import ast
from langchain_core.messages import HumanMessage, AIMessage
from agent import build_workflow

# --- ConfiguraciÃ³n de la PÃ¡gina ---
st.set_page_config(page_title="AI Philosophy Professor", page_icon="ğŸ¦‰", layout="wide")

st.title("ğŸ¦‰ El CatedrÃ¡tico AI: AnÃ¡lisis FilosÃ³fico de la Actualidad")
st.markdown("PropÃ³n un suceso o concepto. Nuestros agentes lo procesarÃ¡n a travÃ©s de **OntologÃ­a, Ã‰tica y EpistemologÃ­a**.Esto es solo una aproximaciÃ³n, no se tiene tomar como una tesis categÃ³rica y contundente.")

# --- InicializaciÃ³n de Estado ---
if "sources" not in st.session_state:
    st.session_state.sources = []
if "messages" not in st.session_state:
    st.session_state.messages = []
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

# --- Sidebar ---
with st.sidebar:
    st.header("ğŸ”‘ Credenciales")
    google_api_key = st.text_input("Google API Key (Gemini)", type="password")
    tavily_api_key = st.text_input("Tavily API Key (BÃºsqueda)", type="password")
    st.info("Pulsa 'Enter' tras introducir las claves.")
    
    st.markdown("---")
    st.header("ğŸ“š BibliografÃ­a EmpÃ­rica")
    sources_placeholder = st.empty()

    if st.session_state.sources:
        with sources_placeholder.container():
            for source in st.session_state.sources:
                st.markdown(f"ğŸ”¹ [{source.get('url', '#')[:35]}...]({source.get('url', '#')})")
    else:
        sources_placeholder.info("Si el tema requiere noticias, aparecerÃ¡n aquÃ­.")

if not (google_api_key and tavily_api_key):
    st.warning("âš ï¸ Introduce tus claves API para despertar al CatedrÃ¡tico.")
    st.stop()

# --- Instanciar Grafo ---
app_workflow = build_workflow(google_api_key, tavily_api_key)

# --- Renderizar Chat ---
for message in st.session_state.messages:
    role = "user" if isinstance(message, HumanMessage) else "assistant"
    with st.chat_message(role):
        st.markdown(message.content)

# --- Input de Usuario ---
if user_input := st.chat_input("Plantea tu tesis o evento..."):
    st.session_state.sources = []
    
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append(HumanMessage(content=user_input))

    inputs = {"messages": [HumanMessage(content=user_input)]}
    config = {"configurable": {"thread_id": st.session_state.thread_id}}
    
    trace_logs = []
    final_response = None

    with st.status("ğŸ›ï¸ El Claustro de Agentes estÃ¡ deliberando...", expanded=True) as status:
        for event in app_workflow.stream(inputs, config=config, stream_mode="values"):
            message = event['messages'][-1]
            
            if isinstance(message, AIMessage):
                sender = message.additional_kwargs.get("sender", "System")
                content = " ".join([str(i) for i in message.content]) if isinstance(message.content, list) else str(message.content)
                
                # Feedback de estado y logs internos    
                if sender == "Investigador":
                    status.write("ğŸ“° **Investigador:** Analizando premisas o buscando datos...")
                    trace_logs.append(f"### ğŸ“° Investigador\n{content}")
                    
                    if "Premisa filosÃ³fica" in content and len(st.session_state.sources) == 0:
                        with sources_placeholder.container():
                            st.info("ğŸ§  AnÃ¡lisis puramente teÃ³rico. No requiere fuentes empÃ­ricas de actualidad.")
                elif sender == "OntologÃ­a":
                    status.write("ğŸ›ï¸ **OntologÃ­a:** Estructurando la esencia del problema...")
                    trace_logs.append(f"### ğŸ›ï¸ OntologÃ­a\n{content}")
                elif sender == "Ã‰tica":
                    status.write("âš–ï¸ **Ã‰tica:** Evaluando tensiones morales...")
                    trace_logs.append(f"### âš–ï¸ Ã‰tica\n{content}")
                elif sender == "EpistemologÃ­a":
                    status.write("ğŸ–‹ï¸ **EpistemologÃ­a:** Sintetizando tesis final...")
                    trace_logs.append(f"### ğŸ–‹ï¸ EpistemologÃ­a\n{content}")
                    final_response = content 
                elif sender == "Tutor Casual":
                    status.write("ğŸ’¬ **Tutor:** Respondiendo de forma conversacional...")
                    trace_logs.append(f"### ğŸ’¬ Tutor Casual\n{content}")
                    final_response = content
                
            elif message.type == "tool" or message.type == "function":
                status.write("ğŸŒ **Buscador:** Fuentes empÃ­ricas recuperadas...")
                
                # Guardamos un log truncado para no saturar la trazabilidad
                content_str = str(message.content)
                trace_logs.append(f"### ğŸŒ Tool Output\n{content_str[:300]}...\n*(Datos completos procesados en memoria)*")
                
                # 1. PARSEO TODOTERRENO
                tool_data = None
                if isinstance(message.content, (list, dict)):
                    tool_data = message.content
                else:
                    try:
                        tool_data = json.loads(message.content)
                    except Exception:
                        try:
                            tool_data = ast.literal_eval(message.content)
                        except Exception:
                            pass
                
                # 2. EXTRACCIÃ“N SEGURA DE FUENTES
                sources_list = []
                if isinstance(tool_data, dict):
                    # Si es el formato nuevo {"results": [...]}
                    sources_list = tool_data.get("results", [])
                elif isinstance(tool_data, list):
                    # Si es el formato antiguo [...]
                    sources_list = tool_data
                
                # 3. FILTRADO (Solo nos quedamos con los que tienen URL vÃ¡lida)
                valid_sources = [s for s in sources_list if isinstance(s, dict) and 'url' in s]
                
                # 4. RENDERIZADO EN EL SIDEBAR
                if valid_sources:
                    st.session_state.sources = valid_sources
                    with sources_placeholder.container():
                        st.markdown("### âœ… Fuentes consultadas:")
                        for source in valid_sources:
                            # Sacamos el tÃ­tulo, o usamos la URL si no hay tÃ­tulo
                            title = source.get('title', source.get('url', 'Enlace externo'))
                            url = source.get('url', '#')
                            st.markdown(f"ğŸ”¹ [{title[:45]}...]({url})")

        status.update(label="Â¡DeliberaciÃ³n completada!", state="complete", expanded=False)

    # --- Renderizado de Respuesta ---
    if final_response:
        clean_text = final_response.replace("TITLE:", "# ").replace("BODY:", "\n\n")
        # Limpieza de fallos residuales de IA
        if "NOTE:" in clean_text:
            clean_text = clean_text.split("NOTE:")[0]
        
        # Eliminamos cualquier cabecera extraÃ±a que la IA intente colar
        clean_text = clean_text.replace("---AnÃ¡lisis Ã‰tico", "").strip()

        with st.chat_message("assistant"):
            st.markdown(clean_text) 
            st.session_state.messages.append(AIMessage(content=clean_text))

    with st.expander("ğŸ” Ver Proceso Cognitivo (Trazabilidad)"):
        for log in trace_logs:
            st.markdown(log)
            st.markdown("---")