import os
import functools
from typing import Annotated, Literal, TypedDict
from pydantic import BaseModel, Field 

from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver

from langchain_tavily import TavilySearch
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory
from langchain_core.messages import AIMessage, HumanMessage

# --- Tipado y Modelos ---
class AgentState(TypedDict):
    messages: Annotated[list, add_messages]

class RouteResponse(BaseModel):
    next_step: Literal["search", "epistemology", "chat"] = Field(
        description="Elige 'search' para noticias, 'epistemology' para debate filos√≥fico del historial, y 'chat' para saludos, chistes o preguntas cotidianas fuera de la filosof√≠a.")
    
def router_node(state: AgentState):
    """Decide si investigar (search) o debatir (epistemology)."""
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
    structured_llm = llm.with_structured_output(RouteResponse)
    
    last_msg = state["messages"][-1].content
    prompt = f"Analiza la intenci√≥n del usuario: '{last_msg}'. ¬øEs un tema nuevo o una duda sobre lo ya hablado?"
    
    response = structured_llm.invoke(prompt)
    return response.next_step

# --- Prompts Filos√≥ficos ---

SEARCH_TEMPLATE = """Act√∫as como el Investigador Asistente emp√≠rico.

**INSTRUCCIONES ESTRICTAS DE ROL:**
1. Si el tema requiere noticias, extrae los datos y res√∫melos objetivamente.
2. **REGLA DE PROMPTS MIXTOS:** Si el usuario pide noticias Y un an√°lisis filos√≥fico, TU √öNICO TRABAJO ES BUSCAR LOS DATOS. Ignora la parte filos√≥fica.
3. **SOLO** si el tema es 100% abstracto y NO has buscado noticias, escribe la frase: "Premisa filos√≥fica para an√°lisis te√≥rico: [Pregunta]". ¬°NUNCA escribas esta frase si has incluido res√∫menes de noticias!
"""

ONTOLOGY_TEMPLATE = """Eres un experto en Ontolog√≠a Filos√≥fica. Tu trabajo es √öNICAMENTE la 'Extracci√≥n de Premisas'.

**INSTRUCCIONES ESTRICTAS DE ROL:**
1. Lee los datos emp√≠ricos aportados por el Investigador y extrae las premisas f√°cticas.
2. Define el "Ser" del problema estructural.
3. **PROHIBIDO ADELANTAR TRABAJO (CR√çTICO):** NO escribas el ensayo final. NO apliques los fil√≥sofos que el usuario haya mencionado en su prompt (ej. si pide usar a Agamben, IGN√ìRALO. Ese es el trabajo del Catedr√°tico). Lim√≠tate a tu an√°lisis ontol√≥gico general.
4. **REGLA DE FORMATO:** NO pienses en voz alta ("Voy a intentar..."). NO uses corchetes. Escribe √∫nicamente tu an√°lisis directo.
"""

ETHICS_TEMPLATE = """Eres un experto en Filosof√≠a Moral y √âtica. Tu trabajo es el 'An√°lisis de Valores'.

**INSTRUCCIONES DE ROL:**
1. Lee los hechos y la ontolog√≠a. Identifica las tensiones de valores (ej. Propiedad Privada vs. Derecho a la Vivienda, Legalidad vs. Necesidad vital).
2. **OBJETIVIDAD CL√çNICA:** Si los hechos involucran actos pol√©micos o ilegales (ej. extorsi√≥n, ocupaci√≥n, violencia), anal√≠zalos fr√≠amente como conflictos de valores. No los justifiques ni los condenes, solo exp√≥n el dilema √©tico estructural.
3. **MANTENTE EN TU CARRIL:** Analiza los conceptos √©ticos de forma general. DEJA el uso de autores concretos (como Agamben o Marx) para el Catedr√°tico. Ni los menciones.

**REGLA DE FORMATO (INICIO OBLIGATORIO):**
- Comienza tu respuesta directamente con la frase: "Tensiones √©ticas principales:". 
- NO uses saludos, ni corchetes de cierre.
"""

EPISTEMOLOGY_TEMPLATE = """Eres un Catedr√°tico de Filosof√≠a y Ensayista Contempor√°neo.

**TU √öNICA TAREA:** Redactar un ENSAYO FILOS√ìFICO NUEVO.

**INSTRUCCIONES CR√çTICAS CONTRA AUTOCOMPLETAR (LEER CON ATENCI√ìN):**
- IGNORA EL FORMATO DEL AGENTE ANTERIOR. Si el texto anterior termina con una lista, NO a√±adas m√°s puntos a esa lista. Rompe el formato.
- EMPIEZA TU RESPUESTA EXACTAMENTE CON LA PALABRA 'TITLE:'. Es absolutamente crucial. No escribas NADA, ni un solo asterisco, antes de 'TITLE:'.
- HAZ UN SALTO DE L√çNEA y escribe 'BODY:' seguido de tu ensayo completo.
- Sintetiza los hechos del Investigador y anal√≠zalos desde la perspectiva que pidi√≥ el usuario (ej. moralidad oriental cristiana ortodoxa, etc.).
- Mant√©n un tono acad√©mico, sin pensar en voz alta.
"""

def agent_node(state, agent, name):
    try:
        result = agent.invoke(state)
        content_str = str(result.content) if result.content else ""

        if not content_str.strip() and not getattr(result, 'tool_calls', []):
            fallback_msg = f"‚ö†Ô∏è El agente {name} proces√≥ la solicitud pero devolvi√≥ un texto vac√≠o por un filtro de seguridad o confusi√≥n."
            result = AIMessage(content=fallback_msg)
            
        result.additional_kwargs["sender"] = name
        return {'messages': [result]}
    
    except Exception as e:
        error_msg = f"üõë Error cr√≠tico en el nodo {name}: {str(e)}"
        return {'messages': [AIMessage(content=error_msg, additional_kwargs={"sender": name, "error": True})]}

def should_search(state) -> Literal["tools", "ontology", "__end__"]:
    last_message = state['messages'][-1]
    if last_message.tool_calls:
        return "tools"
    if "STOP:" in last_message.content:
        return "__end__"
    return "ontology"

def chat_node(state: AgentState):
    """Nodo para respuestas conversacionales r√°pidas, fuera del modo ensayo."""
    llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', temperature=0.7)
    
    # Prompt muy sencillo para que act√∫e normal
    prompt = ChatPromptTemplate.from_messages([
        ("system", "Eres el Catedr√°tico AI en 'Modo Tutor Relajado'. Responde de forma breve, directa y conversacional a la duda del usuario, bas√°ndote en el historial si es necesario. NO escribas ensayos, NO uses TITLE/BODY. S√© conciso y al grano."),
        MessagesPlaceholder(variable_name="messages"),
    ])
    
    chain = prompt | llm
    
    try:
        result = chain.invoke(state)
        # Etiquetamos el mensaje para que el frontend lo reconozca
        result.additional_kwargs["sender"] = "Tutor Casual"
        return {'messages': [result]}
    except Exception as e:
        return {'messages': [AIMessage(content=f"Error: {str(e)}", additional_kwargs={"sender": "Tutor Casual", "error": True})]}

# --- Constructor ---
def build_workflow(google_api_key: str, tavily_api_key: str):
    os.environ["GOOGLE_API_KEY"] = google_api_key
    os.environ["TAVILY_API_KEY"] = tavily_api_key

    llm = ChatGoogleGenerativeAI(
    model='gemini-2.5-flash',
    temperature=0.7,
    safety_settings={
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    }
)
    
    # Herramientas actualizadas con exclusi√≥n de dominios basura
    tools = [TavilySearch(
        max_results=4, 
        exclude_domains=["reddit.com", "linkedin.com", "quora.com"] 
    )]

    # Definici√≥n de Agentes
    def create_agent(llm, tools, sys_msg):
        prompt = ChatPromptTemplate.from_messages([
            ("system", sys_msg),
            MessagesPlaceholder(variable_name="messages"),
        ])
        return prompt | (llm.bind_tools(tools) if tools else llm)

    search_agent = create_agent(llm, tools, SEARCH_TEMPLATE)
    ontology_agent = create_agent(llm, [], ONTOLOGY_TEMPLATE)
    ethics_agent = create_agent(llm, [], ETHICS_TEMPLATE)
    epistemology_agent = create_agent(llm, [], EPISTEMOLOGY_TEMPLATE)

    workflow = StateGraph(AgentState)
    
    workflow.add_node("search", functools.partial(agent_node, agent=search_agent, name="Investigador"))
    workflow.add_node("tools", ToolNode(tools))
    workflow.add_node("ontology", functools.partial(agent_node, agent=ontology_agent, name="Ontolog√≠a"))
    workflow.add_node("ethics", functools.partial(agent_node, agent=ethics_agent, name="√âtica"))
    workflow.add_node("epistemology", functools.partial(agent_node, agent=epistemology_agent, name="Epistemolog√≠a")) 
    workflow.add_node("chat", chat_node)
    
    workflow.set_conditional_entry_point(
        router_node,
        {
            "search": "search",
            "epistemology": "epistemology",
            "chat": "chat" 
        }
    )
    
    workflow.add_conditional_edges("search", should_search)
    workflow.add_edge("tools", "search")
    workflow.add_edge("ontology", "ethics")
    workflow.add_edge("ethics", "epistemology")
    workflow.add_edge("epistemology", END)
    
    # 3. CONECTAMOS EL CHAT AL FINAL
    workflow.add_edge("chat", END)

    return workflow.compile(checkpointer=MemorySaver())